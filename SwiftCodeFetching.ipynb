{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fetching Swift Code Names\n",
    "A fuzzy data augmentation task"
   ],
   "id": "7b696086e067c71d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-13T21:30:54.383095Z",
     "start_time": "2025-02-13T21:30:54.375132Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "xlsx_name = \"UnknownSwiftCodes.xlsx\"\n",
    "\n",
    "api_key_ninja = \"lNMhSMepiZPcgOq8Yj4wXA==L0a2vPJ7AlX1G6G1\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from the Excel file\n",
    "df = pd.read_excel(xlsx_name)\n",
    "\n",
    "# Display the first few rows to understand its structure\n",
    "print(df.head())\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Bank Name\n",
      "0                       Apple Bank for Savings\n",
      "1  Australia and New Zealand Banking Group Ltd\n",
      "2                              Banco BBVA Peru\n",
      "3                    Banco de Credito del Peru\n",
      "4         Banco de Sabadell S.A.Â  Miami Branch\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "15b33e621a5af5d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## All country names",
   "id": "48251f8b6bd8651f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:51:11.872979Z",
     "start_time": "2025-02-13T22:51:11.867537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "countries = [\n",
    "    \"Afghanistan\", \"Albania\", \"Algeria\", \"Andorra\", \"Angola\", \"Antigua and Barbuda\",\n",
    "    \"Argentina\", \"Armenia\", \"Australia\", \"Austria\", \"Azerbaijan\", \"Bahamas\", \"Bahrain\",\n",
    "    \"Bangladesh\", \"Barbados\", \"Belarus\", \"Belgium\", \"Belize\", \"Benin\", \"Bhutan\",\n",
    "    \"Bolivia\", \"Bosnia and Herzegovina\", \"Botswana\", \"Brazil\", \"Brunei\", \"Bulgaria\",\n",
    "    \"Burkina Faso\", \"Burundi\", \"Cabo Verde\", \"Cambodia\", \"Cameroon\", \"Canada\",\n",
    "    \"Central African Republic\", \"Chad\", \"Chile\", \"China\", \"Colombia\", \"Comoros\",\n",
    "    \"Congo, Democratic Republic of the\", \"Congo, Republic of the\", \"Costa Rica\",\n",
    "    \"Cote d'Ivoire\", \"Croatia\", \"Cuba\", \"Cyprus\", \"Czechia\", \"Denmark\", \"Djibouti\",\n",
    "    \"Dominica\", \"Dominican Republic\", \"East Timor\", \"Ecuador\", \"Egypt\", \"El Salvador\",\n",
    "    \"Equatorial Guinea\", \"Eritrea\", \"Estonia\", \"Eswatini\", \"Ethiopia\", \"Fiji\",\n",
    "    \"Finland\", \"France\", \"Gabon\", \"Gambia\", \"Georgia\", \"Germany\", \"Ghana\", \"Greece\",\n",
    "    \"Grenada\", \"Guatemala\", \"Guinea\", \"Guinea-Bissau\", \"Guyana\", \"Haiti\", \"Honduras\",\n",
    "    \"Hungary\", \"Iceland\", \"India\", \"Indonesia\", \"Iran\", \"Iraq\", \"Ireland\", \"Israel\",\n",
    "    \"Italy\", \"Jamaica\", \"Japan\", \"Jordan\", \"Kazakhstan\", \"Kenya\", \"Kiribati\", \"Kosovo\",\n",
    "    \"Kuwait\", \"Kyrgyzstan\", \"Laos\", \"Latvia\", \"Lebanon\", \"Lesotho\", \"Liberia\", \"Libya\",\n",
    "    \"Liechtenstein\", \"Lithuania\", \"Luxembourg\", \"Madagascar\", \"Malawi\", \"Malaysia\",\n",
    "    \"Maldives\", \"Mali\", \"Malta\", \"Marshall Islands\", \"Mauritania\", \"Mauritius\", \"Mexico\",\n",
    "    \"Micronesia\", \"Moldova\", \"Monaco\", \"Mongolia\", \"Montenegro\", \"Morocco\", \"Mozambique\",\n",
    "    \"Myanmar\", \"Namibia\", \"Nauru\", \"Nepal\", \"Netherlands\", \"New Zealand\", \"Nicaragua\",\n",
    "    \"Niger\", \"Nigeria\", \"North Korea\", \"North Macedonia\", \"Norway\", \"Oman\", \"Pakistan\",\n",
    "    \"Palau\", \"Panama\", \"Papua New Guinea\", \"Paraguay\", \"Peru\", \"Philippines\", \"Poland\",\n",
    "    \"Portugal\", \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\", \"Saint Kitts and Nevis\",\n",
    "    \"Saint Lucia\", \"Saint Vincent and the Grenadines\", \"Samoa\", \"San Marino\",\n",
    "    \"Sao Tome and Principe\", \"Saudi Arabia\", \"Senegal\", \"Serbia\", \"Seychelles\",\n",
    "    \"Sierra Leone\", \"Singapore\", \"Slovakia\", \"Slovenia\", \"Solomon Islands\", \"Somalia\",\n",
    "    \"South Africa\", \"South Korea\", \"South Sudan\", \"Spain\", \"Sri Lanka\", \"Sudan\",\n",
    "    \"Suriname\", \"Sweden\", \"Switzerland\", \"Syria\", \"Taiwan\", \"Tajikistan\", \"Tanzania\",\n",
    "    \"Thailand\", \"Togo\", \"Tonga\", \"Trinidad and Tobago\", \"Tunisia\", \"Turkey\",\n",
    "    \"Turkmenistan\", \"Tuvalu\", \"Uganda\", \"Ukraine\", \"United Arab Emirates\",\n",
    "    \"United Kingdom\", \"United States\", \"Uruguay\", \"Uzbekistan\", \"Vanuatu\", \"Vatican City\",\n",
    "    \"Venezuela\", \"Vietnam\", \"Yemen\", \"Zambia\", \"Zimbabwe\"\n",
    "]"
   ],
   "id": "3537c5c5802b2c5c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f185d241cb94089e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using Ninja API",
   "id": "8d433665e58735f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:35:37.780539Z",
     "start_time": "2025-02-13T21:35:37.769956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from thefuzz import fuzz, process  # Library for fuzzy string matching\n",
    "\n",
    "# Load your Excel file\n",
    "file_path =  xlsx_name\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Function to fetch SWIFT codes from the API\n",
    "def fetch_swift_code(bank_name, country=None):\n",
    "    # Format the API URL\n",
    "    if country:\n",
    "        url = f'https://api.api-ninjas.com/v1/swiftcode?bank={bank_name}&country={country}'\n",
    "    else:\n",
    "        url = f'https://api.api-ninjas.com/v1/swiftcode?bank={bank_name}'\n",
    "\n",
    "    headers = {'X-Api-Key': api_key_ninja}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "# Function to extract country from bank name\n",
    "def extract_country(curr_bank_name):\n",
    "    # Fuzzy match the bank name with list of countries\n",
    "    possible_countries = process.extractBests(curr_bank_name, countries, scorer=fuzz.partial_ratio, limit=2, score_cutoff=80)\n",
    "    if possible_countries:\n",
    "        return possible_countries[0][0]  # Return the best match country\n",
    "    return None\n",
    "\n",
    "# Function to parse bank details\n",
    "def parse_swift_codes(row):\n",
    "    curr_bank_name = row\n",
    "    country = extract_country(curr_bank_name)\n",
    "    primary_name = curr_bank_name.split(',')[0].strip()  # Use primary name for the API\n",
    "\n",
    "    # Try with country\n",
    "    swift_results = fetch_swift_code(primary_name, country)\n",
    "\n",
    "    print(swift_results)\n",
    "    # If no results with country, try without country\n",
    "    if not swift_results:\n",
    "        swift_results = fetch_swift_code(primary_name)\n",
    "\n",
    "    us_swift = None\n",
    "    local_swift = None\n",
    "\n",
    "    if swift_results:\n",
    "        for result in swift_results:\n",
    "            if result['country_code'] == 'US':\n",
    "                us_swift = result['swift_code']\n",
    "            if country and result['country'] == country:\n",
    "                local_swift = result['swift_code']\n",
    "\n",
    "    return pd.Series([us_swift, local_swift])\n"
   ],
   "id": "2aa7c4e68d4e770f",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Single entry",
   "id": "a836d89248c23e91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:35:39.328033Z",
     "start_time": "2025-02-13T21:35:38.103904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bank_name = df.loc[36, 'Bank Name']  # Make sure the column name matches your Excel file\n",
    "us_swift_code, local_swift_code = parse_swift_codes(bank_name)\n",
    "\n",
    "print(f\"US SWIFT Code: {us_swift_code}\")\n",
    "print(f\"Local SWIFT Code: {local_swift_code}\")"
   ],
   "id": "4cb227be6e14ab66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "US SWIFT Code: None\n",
      "Local SWIFT Code: None\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Entry looping",
   "id": "5aeb90244d455fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:46:06.815370Z",
     "start_time": "2025-02-13T21:45:24.129265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply parsing function to DataFrame\n",
    "df = pd.read_excel(xlsx_name)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    bank_name = row['Bank Name']\n",
    "    country = extract_country(bank_name)\n",
    "    primary_name = bank_name.split(',')[0].strip()  # Primary name for the API\n",
    "\n",
    "    # Fetch SWIFT codes\n",
    "    swift_results = fetch_swift_code(primary_name, country)\n",
    "\n",
    "    # If no results with country, try without country\n",
    "    if not swift_results:\n",
    "        swift_results = fetch_swift_code(primary_name)\n",
    "\n",
    "    us_swift = None\n",
    "    local_swift = None\n",
    "\n",
    "    # Parse results to find US and local SWIFT codes\n",
    "    if swift_results:\n",
    "        for result in swift_results:\n",
    "            if result['country_code'] == 'US':\n",
    "                us_swift = result['swift_code']\n",
    "            if country and result['country'] == country:\n",
    "                local_swift = result['swift_code']\n",
    "\n",
    "    # Store the SWIFT codes back into the DataFrame\n",
    "    df.at[index, 'US SWIFT Code'] = us_swift\n",
    "    df.at[index, 'Local SWIFT Code'] = local_swift\n",
    "\n",
    "df.to_excel('updated_banks_with_swift_codes.xlsx', index=False)"
   ],
   "id": "6304b37f85418038",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using web-scrapping",
   "id": "b7cf6f2bd7368432"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:42:29.558404Z",
     "start_time": "2025-02-13T21:42:29.556845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Optional, Tuple\n",
    "from Backend.Web_Search.GoogleSearchCaller import GoogleSearchCaller\n",
    "from Backend.Web_Search.QuerySynthesizer import QuerySynthesizer\n",
    "\n",
    "# Suppose you also have a helper function:\n",
    "# from Backend.Web_Search.HTMLArticleScrapper import extract_swift_codes_from_text\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "def extract_swift_codes_from_text(\n",
    "    llm_api_url: str,\n",
    "    text: str,\n",
    "    bank_name: str,\n",
    "    country: str\n",
    ") -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Calls a local LLM (e.g., OLLama) to parse the scraped text for possible\n",
    "    US and local SWIFT codes. Returns (us_swift, local_swift).\n",
    "\n",
    "    If codes aren't found, returns (None, None).\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------- LLM Prompt Instructions -------------------- #\n",
    "    system_msg = (\n",
    "        \"You are an assistant that specializes in extracting SWIFT codes from text. \"\n",
    "        \"We have some text that may contain financial details. \"\n",
    "        \"We want two pieces of data for the bank: the US SWIFT code (if it exists) \"\n",
    "        \"and the local SWIFT code for the bank's main country. \"\n",
    "        \"Return your answer as valid JSON with the shape:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"us_swift_code\": \"...\",\\n'\n",
    "        '  \"local_swift_code\": \"...\"\\n'\n",
    "        \"}\\n\"\n",
    "        \"If you can't find a code, leave it empty (but keep the JSON keys).\"\n",
    "    )\n",
    "\n",
    "    user_msg = (\n",
    "        f\"Bank Name: {bank_name}\\n\"\n",
    "        f\"Country: {country}\\n\\n\"\n",
    "        f\"Text to analyze:\\n{text}\\n\\n\"\n",
    "        \"Please parse out the SWIFT code for the US branch (if any) \"\n",
    "        \"and the local SWIFT code for the bank in its home country.\"\n",
    "    )\n",
    "\n",
    "    # -------------------- HTTP Payload for LLM -------------------- #\n",
    "    payload = {\n",
    "        \"model\": \"llama2:latest\",  # or whichever model your local LLM server expects\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    # -------------------- Make LLM Request -------------------- #\n",
    "    try:\n",
    "        response = requests.post(llm_api_url, headers=headers, json=payload, timeout=120)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "        # Example: OLLama returns the final text in data[\"message\"][\"content\"]\n",
    "        llm_text = data.get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "\n",
    "        # Attempt to parse out JSON\n",
    "        us_swift = None\n",
    "        local_swift = None\n",
    "\n",
    "        try:\n",
    "            parsed = json.loads(llm_text)\n",
    "            us_swift = parsed.get(\"us_swift_code\")       # might be None if missing\n",
    "            local_swift = parsed.get(\"local_swift_code\") # might be None if missing\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"[WARN] Could not decode LLM response as JSON.\")\n",
    "\n",
    "        return us_swift, local_swift\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"[ERROR] LLM request failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def scrape_and_extract_swift_codes(\n",
    "    bank_name: str,\n",
    "    country: Optional[str],\n",
    "    llm_api_url: str,\n",
    "    google_caller: GoogleSearchCaller,  # Pass an instantiated GoogleSearchCaller\n",
    "    google_api_key: str,\n",
    "    google_cse_id: str,\n",
    "    max_pages: int = 3\n",
    ") -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"\n",
    "    1) Generate search queries for the bank via LLM\n",
    "    2) For each query, run Google Custom Search -> parse results\n",
    "    3) Accumulate text -> pass to LLM for SWIFT code extraction\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Generate queries via LLM\n",
    "    q_synth = QuerySynthesizer(llm_api_url=llm_api_url)\n",
    "    prompt = f\"Find the official SWIFT codes for {bank_name} in {country}.\"\n",
    "    queries = q_synth.generate_search_prompts(prompt)\n",
    "\n",
    "    all_text = []\n",
    "\n",
    "    # 2) For each query, run a Custom Search + parse the result URLs\n",
    "    for query in queries:\n",
    "        # Call the custom search API to get raw search items\n",
    "        search_items = google_caller.run_custom_search(\n",
    "            query,\n",
    "            api_key=google_api_key,\n",
    "            cse_id=google_cse_id,\n",
    "            num_results=max_pages\n",
    "        )\n",
    "\n",
    "        # Extract the URLs from the search items\n",
    "        urls = [item[\"link\"] for item in search_items if \"link\" in item]\n",
    "\n",
    "        # Parse the content of each URL\n",
    "        parsed_items = google_caller.parse_urls(urls)\n",
    "        for item in parsed_items:\n",
    "            main_content = item.get(\"Main_Content\", \"\")\n",
    "            if main_content:\n",
    "                all_text.append(main_content)\n",
    "\n",
    "    # Combine everything into one big text chunk\n",
    "    combined_text = \"\\n\\n\".join(all_text)\n",
    "\n",
    "    # 3) Use LLM to parse out SWIFT codes from the aggregated text\n",
    "    us_swift, local_swift = extract_swift_codes_from_text(\n",
    "        llm_api_url=llm_api_url,\n",
    "        text=combined_text,\n",
    "        bank_name=bank_name,\n",
    "        country=country or \"\"\n",
    "    )\n",
    "\n",
    "    return us_swift, local_swift"
   ],
   "id": "9aee746cd3477e6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Merging both methodologies",
   "id": "c8eef712d72bf916"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Single entry",
   "id": "f37f817d1187f051"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:51:27.768969Z",
     "start_time": "2025-02-13T22:51:27.765406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "# Your existing imports:\n",
    "# from Backend.Web_Search.GoogleSearchCaller import GoogleSearchCaller\n",
    "# from Backend.Web_Search.QuerySynthesizer import QuerySynthesizer\n",
    "# from Backend.Web_Search.extract_swift_codes import extract_swift_codes_from_text\n",
    "# from ... (wherever you placed scrape_and_extract_swift_codes)\n",
    "\n",
    "\n",
    "from Backend.Web_Search.GoogleSearchCaller import GoogleSearchCaller\n",
    "from Backend.Web_Search.QuerySynthesizer import QuerySynthesizer\n",
    "\n",
    "# Create the GoogleSearchCaller\n",
    "google_caller = GoogleSearchCaller(\n",
    "    download_dir=\"downloaded_files\",  # or any directory to store PDF downloads\n",
    "    concurrency=2,                   # or 1, or more, depending on your needs\n",
    "    min_delay=1.0,\n",
    "    max_delay=2.5,\n",
    "    use_proxies=False\n",
    ")\n"
   ],
   "id": "982adde07f096f95",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T00:26:11.246125Z",
     "start_time": "2025-02-13T22:51:33.825189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Jupyter Notebook Cell\n",
    "\n",
    "# --- 1) Imports ---\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# If they're in the same folder or accessible by Python path, just do:\n",
    "from Backend.Web_Search.GoogleSearchCaller import GoogleSearchCaller\n",
    "from Backend.Web_Search.QuerySynthesizer import QuerySynthesizer\n",
    "# E.g.:\n",
    "# from your_module.HTMLArticleScrapper import HTMLArticleScrapper\n",
    "# from your_module.MyGoogleSearchCaller import MyGoogleSearchCaller\n",
    "\n",
    "# If you have a custom \"MyGoogleSearchCaller\" that disables SSL, you can import it instead:\n",
    "# from Backend.Web_Search.MyGoogleSearchCaller import MyGoogleSearchCaller\n",
    "\n",
    "# For this demo, we'll just use GoogleSearchCaller directly.\n",
    "# If you do want SSL disabled, see your existing \"MyGoogleSearchCaller\" code snippet.\n",
    "\n",
    "##############################################################################\n",
    "# 2) Configuration: Keys, LLM URL\n",
    "##############################################################################\n",
    "api_key_ninja = \"lNMhSMepiZPcgOq8Yj4wXA==L0a2vPJ7AlX1G6G1\"  # API Ninjas\n",
    "llm_api_url   = \"http://localhost:11434/api/chat\"         # Local LLM endpoint\n",
    "google_api_key = \"AIzaSyB84u4teNOuRSr58MlCaHKLDeyMlXN4JV4\"\n",
    "google_cse_id  = \"25ea2aec2a0064008\"\n",
    "\n",
    "##############################################################################\n",
    "# 3) Helper: Try API Ninjas\n",
    "##############################################################################\n",
    "def fetch_swift_code(bank_name: str, country: Optional[str] = None):\n",
    "    \"\"\"Calls API Ninjas SWIFT code endpoint.\"\"\"\n",
    "    if country:\n",
    "        url = f\"https://api.api-ninjas.com/v1/swiftcode?bank={bank_name}&country={country}\"\n",
    "    else:\n",
    "        url = f\"https://api.api-ninjas.com/v1/swiftcode?bank={bank_name}\"\n",
    "\n",
    "    headers = {\"X-Api-Key\": api_key_ninja}\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()  # Usually a list of dict with swift_code, country_code, etc.\n",
    "    return None\n",
    "\n",
    "##############################################################################\n",
    "# 4) LLM-Powered Extraction from a text block\n",
    "##############################################################################\n",
    "def extract_swift_codes_from_text(llm_api_url: str, text: str, bank_name: str, country: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"Calls local LLM to parse possible US/local SWIFT codes from text.\"\"\"\n",
    "    system_msg = (\n",
    "        \"You are an assistant that specializes in extracting SWIFT codes from text. \"\n",
    "        \"We want two pieces of data for the bank: the US SWIFT code (if it exists) \"\n",
    "        \"and the local SWIFT code for the bank's main country. Return them as JSON:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"us_swift_code\": \"...\",\\n'\n",
    "        '  \"local_swift_code\": \"...\" \\n'\n",
    "        \"}\"\n",
    "    )\n",
    "\n",
    "    user_msg = f\"Bank Name: {bank_name}\\nCountry: {country}\\n\\nText:\\n{text}\\n\\n\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama2:latest\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        r = requests.post(llm_api_url, json=payload, headers=headers, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        llm_text = data.get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "\n",
    "        us_swift = None\n",
    "        local_swift = None\n",
    "        try:\n",
    "            parsed_json = json.loads(llm_text)\n",
    "            us_swift = parsed_json.get(\"us_swift_code\")\n",
    "            local_swift = parsed_json.get(\"local_swift_code\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"[WARN] Could not parse LLM JSON response.\")\n",
    "\n",
    "        return us_swift, local_swift\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"[ERROR] LLM request failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "##############################################################################\n",
    "# 5) Fallback: LLM + Google\n",
    "##############################################################################\n",
    "def scrape_and_extract_swift_codes(\n",
    "    bank_name: str,\n",
    "    country: Optional[str],\n",
    "    llm_api_url: str,\n",
    "    google_caller: GoogleSearchCaller,\n",
    "    google_api_key: str,\n",
    "    google_cse_id: str,\n",
    "    max_pages: int = 3\n",
    ") -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"\n",
    "    1) Generate ~5 queries via LLM\n",
    "    2) Google them -> parse text\n",
    "    3) Pass text to LLM to parse out SWIFT codes\n",
    "    \"\"\"\n",
    "    q_synth = QuerySynthesizer(llm_api_url=llm_api_url)\n",
    "    prompt = f\"Find official SWIFT codes for {bank_name} in {country or '??'}\"\n",
    "    search_queries = q_synth.generate_search_prompts(prompt)\n",
    "\n",
    "    all_texts = []\n",
    "\n",
    "    for q in search_queries:\n",
    "        # get list of search items\n",
    "        items = google_caller.run_custom_search(q, google_api_key, google_cse_id, num_results=max_pages)\n",
    "        # parse URLs\n",
    "        urls = [it[\"link\"] for it in items if \"link\" in it]\n",
    "        parse_results = google_caller.parse_urls(urls)\n",
    "        # collect main text\n",
    "        for doc in parse_results:\n",
    "            if doc.get(\"Main_Content\"):\n",
    "                all_texts.append(doc[\"Main_Content\"])\n",
    "\n",
    "    combined_text = \"\\n\\n\".join(all_texts)\n",
    "    us_swift, local_swift = extract_swift_codes_from_text(\n",
    "        llm_api_url=llm_api_url,\n",
    "        text=combined_text,\n",
    "        bank_name=bank_name,\n",
    "        country=country or \"\"\n",
    "    )\n",
    "    return us_swift, local_swift\n",
    "\n",
    "##############################################################################\n",
    "# 6) Actually run the logic for a single bank name\n",
    "##############################################################################\n",
    "\n",
    "def fuzzy_guess_country(bank_name: str) -> Optional[str]:\n",
    "    \"\"\"Simple fuzzy guess from the small list above.\"\"\"\n",
    "    from thefuzz import process, fuzz\n",
    "    if not countries:\n",
    "        return None\n",
    "    guesses = process.extractBests(bank_name, countries, scorer=fuzz.partial_ratio, limit=1, score_cutoff=80)\n",
    "    if guesses:\n",
    "        return guesses[0][0]\n",
    "    return None\n",
    "\n",
    "# 6b) Instantiate the GoogleSearchCaller\n",
    "google_caller = GoogleSearchCaller(\n",
    "    download_dir=\"downloaded_files\",\n",
    "    concurrency=1,\n",
    "    min_delay=1.0,\n",
    "    max_delay=2.0,\n",
    "    use_proxies=False\n",
    ")\n",
    "\n",
    "# 6c) Test for a single bank\n",
    "bank_name = \"Scotia Panama Trust Co. S.A.\"  # could include a country phrase if you want\n",
    "country_guess = fuzzy_guess_country(bank_name)\n",
    "\n",
    "# 1) Attempt API\n",
    "swift_api_results = fetch_swift_code(bank_name, country_guess)\n",
    "if not swift_api_results:\n",
    "    # if no result with guessed country, try without\n",
    "    swift_api_results = fetch_swift_code(bank_name)\n",
    "\n",
    "us_swift_code, local_swift_code = None, None\n",
    "if swift_api_results:\n",
    "    for r in swift_api_results:\n",
    "        if r.get(\"country_code\") == \"US\":\n",
    "            us_swift_code = r[\"swift_code\"]\n",
    "        # if country guessed matches the \"country\" in the result\n",
    "        if country_guess and r.get(\"country\") == country_guess:\n",
    "            local_swift_code = r[\"swift_code\"]\n",
    "\n",
    "# 2) If both remain None => fallback\n",
    "if not us_swift_code and not local_swift_code:\n",
    "    print(f\"[INFO] No SWIFT from API => searching & scraping for '{bank_name}'\")\n",
    "    fallback_us, fallback_local = scrape_and_extract_swift_codes(\n",
    "        bank_name=bank_name,\n",
    "        country=country_guess,\n",
    "        llm_api_url=llm_api_url,\n",
    "        google_caller=google_caller,\n",
    "        google_api_key=google_api_key,\n",
    "        google_cse_id=google_cse_id,\n",
    "        max_pages=3\n",
    "    )\n",
    "    us_swift_code = fallback_us or us_swift_code\n",
    "    local_swift_code = fallback_local or local_swift_code\n",
    "\n",
    "# 3) Print final\n",
    "print(\"\\n=== FINAL RESULT ===\")\n",
    "print(\"Bank Name:\", bank_name)\n",
    "print(\"Guessed Country:\", country_guess)\n",
    "print(\"US SWIFT Code:\", us_swift_code)\n",
    "print(\"Local SWIFT Code:\", local_swift_code)"
   ],
   "id": "67ad67450be76b12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] No SWIFT from API => searching & scraping for 'Scotia Panama Trust Co. S.A.'\n",
      "Raw LLM Response: {'model': 'llama3.3:latest', 'created_at': '2025-02-13T22:51:49.044647Z', 'message': {'role': 'assistant', 'content': '{\\n  \"search_prompts\": [\\n    \"Scotia Panama Trust Co. S.A. SWIFT code\",\\n    \"SWIFT code for banks in Panama Scotia Panama Trust\",\\n    \"Official SWIFT code Scotia Panama Trust Co. S.A.\",\\n    \"Scotia Panama Trust Co. S.A. Panama SWIFT code filetype:pdf\",\\n    \"Panama bank SWIFT codes Scotia Panama Trust Co. S.A. filetype:pdf\"\\n  ]\\n}'}, 'done_reason': 'stop', 'done': True, 'total_duration': 13794018958, 'load_duration': 35338250, 'prompt_eval_count': 166, 'prompt_eval_duration': 4148000000, 'eval_count': 95, 'eval_duration': 9606000000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:51:54,898 [ERROR] Request failed for https://help.bill.com/s/article/360007172671: HTTPSConnectionPool(host='help.bill.com', port=443): Max retries exceeded with url: /s/article/360007172671 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 466, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 1095, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connection.py\", line 730, in connect\n",
      "    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connection.py\", line 909, in _ssl_wrap_socket_and_match_hostname\n",
      "    ssl_sock = ssl_wrap_socket(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 469, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 513, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/ssl.py\", line 517, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/ssl.py\", line 1104, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/ssl.py\", line 1382, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 490, in _make_request\n",
      "    raise new_e\n",
      "urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/util/retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='help.bill.com', port=443): Max retries exceeded with url: /s/article/360007172671 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luislascano01/Documents/Sabadell/CreditAnalysisGPT/Backend/Web_Search/GoogleSearchCaller.py\", line 263, in _handle_html\n",
      "    response = requests.get(url, headers=headers, timeout=10, proxies=proxies)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/adapters.py\", line 698, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='help.bill.com', port=443): Max retries exceeded with url: /s/article/360007172671 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "2025-02-13 17:52:01,059 [ERROR] Request failed for https://help.bill.com/s/article/360007172671: HTTPSConnectionPool(host='help.bill.com', port=443): Max retries exceeded with url: /s/article/360007172671 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 466, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 1095, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connection.py\", line 730, in connect\n",
      "    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connection.py\", line 909, in _ssl_wrap_socket_and_match_hostname\n",
      "    ssl_sock = ssl_wrap_socket(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 469, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 513, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/ssl.py\", line 517, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/ssl.py\", line 1104, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/ssl.py\", line 1382, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 490, in _make_request\n",
      "    raise new_e\n",
      "urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/util/retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='help.bill.com', port=443): Max retries exceeded with url: /s/article/360007172671 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luislascano01/Documents/Sabadell/CreditAnalysisGPT/Backend/Web_Search/GoogleSearchCaller.py\", line 263, in _handle_html\n",
      "    response = requests.get(url, headers=headers, timeout=10, proxies=proxies)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/adapters.py\", line 698, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='help.bill.com', port=443): Max retries exceeded with url: /s/article/360007172671 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "2025-02-13 17:52:04,804 [ERROR] Request failed for https://help.bill.com/s/article/360007172671: HTTPSConnectionPool(host='help.bill.com', port=443): Max retries exceeded with url: /s/article/360007172671 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 466, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 1095, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connection.py\", line 730, in connect\n",
      "    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connection.py\", line 909, in _ssl_wrap_socket_and_match_hostname\n",
      "    ssl_sock = ssl_wrap_socket(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 469, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 513, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/ssl.py\", line 517, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/ssl.py\", line 1104, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/ssl.py\", line 1382, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 490, in _make_request\n",
      "    raise new_e\n",
      "urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/urllib3/util/retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='help.bill.com', port=443): Max retries exceeded with url: /s/article/360007172671 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luislascano01/Documents/Sabadell/CreditAnalysisGPT/Backend/Web_Search/GoogleSearchCaller.py\", line 263, in _handle_html\n",
      "    response = requests.get(url, headers=headers, timeout=10, proxies=proxies)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luislascano01/miniconda3/envs/CreditAnalysisGPT/lib/python3.11/site-packages/requests/adapters.py\", line 698, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='help.bill.com', port=443): Max retries exceeded with url: /s/article/360007172671 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] LLM request failed: 404 Client Error: Not Found for url: http://localhost:11434/api/chat\n",
      "\n",
      "=== FINAL RESULT ===\n",
      "Bank Name: Scotia Panama Trust Co. S.A.\n",
      "Guessed Country: Panama\n",
      "US SWIFT Code: None\n",
      "Local SWIFT Code: None\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T00:26:11.254692Z",
     "start_time": "2025-02-14T00:26:11.253691Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9eeb998d7ae6ea94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7d0eeafd0f8c623e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
